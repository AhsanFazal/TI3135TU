{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8e957d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4e878e4c62444d6fb4f6a94f90579b5",
     "grade": false,
     "grade_id": "cell-9ba2d0bc08f4ac04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 1\n",
    "This assignment consists of one notebook file. Each exercise is graded using *hidden* tests. If you pass these tests then you are rewarded *full points* for that exercise; if your code fails the tests in any way then you will get *no points* for that exercise. Make sure to **read the rules** before you start the assignment.\n",
    "\n",
    "## Rules\n",
    "For this assignment the following rules apply:\n",
    "\n",
    "**General**\n",
    " * The assignment should be completed in **groups of two or three** (enroll in a group on Brightspace).\n",
    " * Any kind of intergroup discussion will be considered fraud and both the parties will be punished.\n",
    " * All code must be written intra group. All external help, with the exception of Python/library documentation and the lecture slides, will be considered fraud.\n",
    " * Do not use libraries that implement the assignment for you (e.g. don't use `cv2.cvtColor` to do color to gray conversion). Ask a TA if you are unsure.\n",
    "\n",
    "**Grading**\n",
    " * Each exercise is graded using additional hidden tests. These tests will check your solution for different (unseen) inputs.\n",
    " * If the tests pass without error (warnings are allowed) then you receive full points.\n",
    " * If the tests fail or raise an exception for any reason then you receive 0 points.\n",
    " * If a test cell takes more than five minutes to complete then this is considered an error.\n",
    " * Do not make any assumptions on the input data (such as resolution) unless specified otherwise. Doing so may result in the tests failing and thus 0 points.\n",
    " * Your grade is computed as $\\frac{\\text{points}}{\\text{max_points}} * 9 + 1$ and will be rounded to the closest 0.5 point.\n",
    " * Submit your code to Brightspace as a zip file containing only the notebook (`*.ipynb`) files.\n",
    " * **Do not rename the notebook files**\n",
    " \n",
    "**Late Submissions**\n",
    " * Late submissions must be submitted *as soon as possible* to the \"Assignment 1 - Late Submissions\" assignment on Brightspace.\n",
    " * The following penalty will be applied: $\\text{adjusted grade} = \\text{grade} - 1 - \\lceil\\frac{\\text{minutes late}}{10}\\rceil$\n",
    "\n",
    "<br />\n",
    " \n",
    "**Before you submit**, make sure that you are not accidentaly using any global variables. Restart the kernel (wiping all global variables) and run the code from top to bottom by clicking \"Kernel\" => \"Restart & Run all\" in the menu bar at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a640d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbea3b36829767526a39070f6252f2af",
     "grade": false,
     "grade_id": "cell-aadbf94937f58ce3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import helpers\n",
    "\n",
    "# Load a image, resize (optional) and convert it to a normalized floating point format (map values between 0.0 and 1.0).\n",
    "#image = helpers.imread_normalized_float(\"name_of_image_file.png\")\n",
    "\n",
    "# Show a single image\n",
    "#helpers.show_image(image, \"Text above image\")\n",
    "    \n",
    "# Showing multiple images in a grid (with a given number of rows and columns):\n",
    "# helpers.show_images({\"Text above figure1\": figure1, \"Text above figure2\": \"figure2\"}, nrows, ncols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df3841",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef3eb0ecb98dc7b4ceff2db6bd04cad4",
     "grade": false,
     "grade_id": "cell-7637c9dfb4f7d331",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Color Images\n",
    "Light consists of a combination of electromagnatic waves at different wave lengths. Our eyes can capture a part of this spectrum using \"cones\" which capture short, medium, and long wavelengths. These absorption spectra map to roughly red, green, and blue respectively. Hence, the colors of pixels are typically stored as a combination of red, green, and blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c05dd9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "664c5dc2cbceec823bc7178c1d440c44",
     "grade": false,
     "grade_id": "cell-ec9941c924912744",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import color_spaces\n",
    "color_spaces.draw_rgb_circle_diagram(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfceef7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03e7030f1e4f0e92e428e6d0e9600dd7",
     "grade": false,
     "grade_id": "cell-22dfb94545cf7deb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1 (1 point)\n",
    "RGB (Red, Green, Blue) maps nicely to the human visual system. However, for image progressing we sometimes prefer other color spaces such as YIQ which separate color from luminance. The formula to convert from RGB to YIQ is as follows:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "Y \\\\\n",
    "I \\\\\n",
    "Q\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.299 & 0.587 & 0.114 \\\\\n",
    "0.595716 & -0.274453 & -0.321263 \\\\\n",
    "0.211456 & -0.522591 & 0.311135\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "R \\\\\n",
    "G \\\\\n",
    "B\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Your job is to implement a function which converts any image from RGB to the YIQ color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c2184",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93affd9ca450bab101ef9d9edf343952",
     "grade": false,
     "grade_id": "exercise1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def rgb_to_yiq(image):\n",
    "    out = np.empty(image.shape)\n",
    "     # YOUR CODE HERE\n",
    "     raise NotImplementedError()\n",
    "    return out\n",
    "\n",
    "new_york_image = helpers.imread_normalized_float(os.path.join(helpers.dataset_folder, \"week1\", \"rework\", \"newyork.jpg\"), 0.25) # Downscale by 4 in each direction = 16 times less pixels.\n",
    "new_york_image_yiq = rgb_to_yiq(new_york_image)\n",
    "\n",
    "helpers.show_image(new_york_image, \"Input Image (RGB)\")\n",
    "\n",
    "print(\"YOUR SOLUTION:\")\n",
    "fig, axis = plt.subplots(1,3, figsize=(9.5, 3))\n",
    "plot_names = [\"Y luminance\", \"I chrominance\", \"Q chrominance\"]\n",
    "for i, ax in enumerate(axis):\n",
    "    ax.set_title(plot_names[i])\n",
    "    ax.imshow(new_york_image_yiq[:,:,i], cmap=(\"gray\" if i==0 else \"viridis\"))\n",
    "    ax.axis(\"off\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1df160",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "043625dccb6b634a6c33c0b0284e1d32",
     "grade": false,
     "grade_id": "cell-b82cc6b100fa14b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 1\n",
    "The grading tests for this solution are hidden. However, you should be able to get a good idea of whether the code is doing what you expect it to do by comparing the results to that you work out by hand. For a complicated image this is hard, so we provide a small test \"image\" that you can use. Do not worry if the results of your function are off by a very tiny amount ($<0.0001$), this is to be expected due to the limited precision with which computers can represent floating point numbers.\n",
    "\n",
    "*You are free to modify the provided tests in any way you want. They are not part of the grading*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.array([[\n",
    "    [0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [0, 1, 1], [1, 1, 1]\n",
    "]])\n",
    "yiq_image = rgb_to_yiq(test_image)\n",
    "\n",
    "np.set_printoptions(precision=3) # Print at most 3 decimals\n",
    "for i in range(test_image.shape[1]):\n",
    "    rgb = test_image[:,i,:]\n",
    "    yiq = yiq_image[:,i,:]\n",
    "    print(f\"RGB: {rgb}\")\n",
    "    print(f\"YIQ: {yiq}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bf93a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8325cdc2e862f820c532fc20258b56c",
     "grade": true,
     "grade_id": "exercise1_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a458a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17c8819326ba0f45685a6ab396968c9e",
     "grade": false,
     "grade_id": "cell-c9ab343d98f644a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Contrast\n",
    "You might be familiar with the various filters on your phone that make the colors in your images stand out more. These filters do so by increasing the contrast of the image. Contrast is defined as the difference between the pixel with the lowest and the pixel with the highest intensity. Let's consider the image of this car for example. The \"colors\" (this is in gray scale) are washed out: the image has a low contrast.\n",
    "\n",
    "Another way we can reason about the contrast of an image is by examining the intensity histogram. A histogram is a collection of bins, each of which stores the frequency of occurances of a certain value range. In the case of images, the values are a color or intensity; so a histogram tells us for each bin how many pixels have an intensity within that range. Next to the car we have plotted a  histogram of the image. Notice how almost all pixels have an intensity between 0.3 and 0.7. The contrast is thus only $0.7-0.3=0.4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97736e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b4c064209391080b149ce408c743bc6",
     "grade": false,
     "grade_id": "cell-7ed6cb03f64b36ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "car_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"car.png\"))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=helpers.default_fig_size)\n",
    "ax1.imshow(car_image, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax1.set_axis_off()\n",
    "ax2.hist(car_image.flatten(), 20, range=(0, 1))\n",
    "ax2.set_xlabel(\"Intensity (gray scale)\")\n",
    "ax2.set_ylabel(\"Number of pixels\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0528ab78",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fdcc50b3ca0758dc53e07d7ab8a63394",
     "grade": false,
     "grade_id": "cell-d19376beae79447f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2 (1 point)\n",
    "A simple way to increase the contract of an image is through Automatic Contrast Adjustment. Automatic Contrast Adjustment \"stretches\" the contrast by linearly interpolating the intensity values such that the new min/max intensity of the image lies inside a new target range. Implement a function that stretches the contrast such that the new intensities range from/to the given minimum/maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e6ed1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "617a56fc328ca94141533016ba62e1b6",
     "grade": false,
     "grade_id": "exercise2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def constrast_stretch(gray_image, target_minimum_intensity, target_maximum_intensity):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "car_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"car.png\"))\n",
    "car_image_stretched = constrast_stretch(car_image, -0.2, 1.2)\n",
    "helpers.show_images({ \"Original\": car_image, \"Your solution (stretched contrast)\": car_image_stretched }, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ba2b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "200ac79116dcd30898e41454b1c3e98a",
     "grade": false,
     "grade_id": "cell-3e4b2293ee1ad658",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 2\n",
    "You can verify whether you think your solution is working by analyzing the histogram of the output image for different minimum/maximum target intensities. Do the results match your expectation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_minimum_intensity = -0.2\n",
    "target_maximum_intensity = 1.2\n",
    "\n",
    "car_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"car.png\"))\n",
    "car_image_stretched = constrast_stretch(car_image, target_minimum_intensity, target_maximum_intensity)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=helpers.default_fig_size)\n",
    "ax1.imshow(car_image_stretched, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax1.set_axis_off()\n",
    "ax2.hist(car_image_stretched.flatten(), 20)\n",
    "ax2.set_xlabel(\"Intensity (gray scale)\")\n",
    "ax2.set_ylabel(\"Number of pixels\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb93d90",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6bd717f78b69922022d751a4da1f7be",
     "grade": true,
     "grade_id": "exercise2_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa717b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea857192f0bde58d3ba18cbfa381cf62",
     "grade": false,
     "grade_id": "cell-44ace061ec2b5d10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3 (1 point)\n",
    "In a real application contrast enhancement should work without the intervention of the user. A naive approach would be to always map the input image to a range of $0.0$ and $1.0$. However, this fails in cases where the input image already has a couple of pixels that reach close to $0.0$ and $1.0$. These pixels are not representative of the whole image and prevent proper stretching with the naive approach.\n",
    "\n",
    "![Modified Auto Contrast](images/modified_auto_contrast.png)\n",
    "\n",
    "Modified Auto-Contrast tries to alleviate this issue by saturating a given percentage ($p_\\text{lo}, p_\\text{hi}$) of pixels at the lower and upper ends respectively. Saturating means that those pixels may exceed the range of $[0, 1]$ after stretching. This is achieved by computing the pixel values $a'_\\text{lo}$ and $a'_\\text{hi}$ (see lecture slides & image above) for which $p_{lo}$ / $p_\\text{hi}$ percentage of the pixels is lower or higher respectively.\n",
    "\n",
    "Implement the auto contrast function described above. Clamp the result such that the output pixels lie in the range of $[0, 1]$.\n",
    "\n",
    "**Tip**: `np.percentile` ([documentation](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)) may help you to compute $a'_\\text{lo}$ and $a'_\\text{hi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f2f7a6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1343fc3d102f96c53764d74e38bb5f41",
     "grade": false,
     "grade_id": "exercise3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def auto_contrast(gray_image, p_lo, p_hi):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "car_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"colors\", \"bridge.png\"))\n",
    "car_image_stretched = auto_contrast(car_image, 5, 20)\n",
    "helpers.show_images({ \"Original\": car_image, \"Your solution (auto contrast)\": car_image_stretched }, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f6250",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ae1a83a942915df3f18505284df30da",
     "grade": false,
     "grade_id": "cell-8889816bd987d2c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 3\n",
    "A good way to verify your solution is by creating a very simple test input (e.g., as provided for exercise 1) and checking the resulting histogram. Try to come up with an easy test case to verify whether your solution is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c924c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = np.array([22, 4, 16]) # REPLACE THIS WITH YOUR TEST INPUT\n",
    "output_image = auto_contrast(input_image, 10, 10)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=helpers.default_fig_size)\n",
    "ax.set_title(\"Histogram\")\n",
    "ax.hist(output_image, 100)\n",
    "ax.set_xlabel(\"Intensity (gray scale)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9e69a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff1fd62ca178f4b817710eeaf9fcd113",
     "grade": true,
     "grade_id": "exercise3_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4267a95",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c10bf1e8288199ffe18cdb4a5811c38",
     "grade": false,
     "grade_id": "cell-1b362e16026c57b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Image Filters\n",
    "Apart from very simple per-pixel operations (such as color inversion) we can also design filters that take into account a neighbourhood around a pixel. A popular way of formulating and applying these filters is through the use of the convolution operator. The convolution operator applies a weighted sum to the surrounding pixels for each output pixel. The weights of the weighted sum are organized in an array (called kernel). The kernel is centered around the pixel that is currently computed (hence the size of the kernel should always be uneven) - compare the slides on box filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd436791",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94a97a0fe3e35411e9940874c22c046d",
     "grade": false,
     "grade_id": "cell-4d3c2a9e3b2e94f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 4 (1 point)\n",
    "The basic Laplace filter computes the differences between a central pixel and the weighted average of the neighboring pixels. This difference, multiplied by some weight, can be added or subtracted from the original image to smooth or sharpen the image respectively.\n",
    "\n",
    "Implement the two functions that smoothen or sharpen the input image using the Laplace filter with the given weight. Use `scipy.signal.correlate2d(image, kernel, mode=\"same\")` to apply your convolution (recall the similarities between *correlate* and *convolve* mentioned in the lecture). More information on the Laplace filter can be found in the lecture slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394e130",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18245f00a30c3ec2600493c616f3c946",
     "grade": false,
     "grade_id": "exercise4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def laplace_smooth(gray_image, weight):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def laplace_sharpen(gray_image, weight):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "cricket_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"rework\", \"blurry.png\"))\n",
    "smoothed_image = laplace_smooth(cricket_image, 5)\n",
    "sharpened_image = laplace_sharpen(cricket_image, 5)\n",
    "helpers.show_images({\n",
    "    \"Original\": cricket_image,\n",
    "    \"Your solution (smoothed)\": smoothed_image,\n",
    "    \"Your solution (sharpened)\": sharpened_image\n",
    "}, nrows=1, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c99eb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6e77d1476919c07e72a51bf3c189d3f",
     "grade": true,
     "grade_id": "exercise4_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Makes sure that the image you output has the same dimensions as the input\n",
    "cricket_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"rework\", \"blurry.png\"))\n",
    "smoothed_image = laplace_smooth(cricket_image, 5)\n",
    "sharpened_image = laplace_sharpen(cricket_image, 5)\n",
    "assert(smoothed_image.shape == cricket_image.shape)\n",
    "assert(sharpened_image.shape == cricket_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb8180c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96476d409ad2a9a78a6a34601d14b3a6",
     "grade": false,
     "grade_id": "cell-0dabf07872c876dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Separable Convolution\n",
    "Linear convolution filters can become quite expensive to execute because their performance grows with the filter size. In 2D this means that if we double the horizontal & vertical resolution then we quadrupal the number of operations required to execute the filter.\n",
    "\n",
    "Some convolution filters are separable, meaning that they can be separated into a vertical and horizontal component. For this we use of the associative property of convolution, namely that: $(a \\circledast b) \\circledast c = a \\circledast (b \\circledast c)$. In this case the kernel can be decomposed as the result of a convolution of a horizontal and vertical (1D) kernel. Applying these two 1D kernels to the original input dataset ($a$ in the previous example) will give the same result as applying a convolution with the full 2D kernel.\n",
    "\n",
    "The performance advantage comes from the fact that a $MxN$ kernel is now decomposed into a $Mx1$ and $1xN$ kernel. This reduces the number of operations that need to be performed per pixel from $M \\cdot N$ to $M + N$.\n",
    "\n",
    "### Exercise 5 (1 point)\n",
    "Break down the following smoothing convolution kernel into a horizontal and vertical component. The result of convolution with those two 1D kernels should be the same as a convolution with the 2D kernel.\n",
    "$$\n",
    "\\frac{1}{22}\n",
    "\\begin{bmatrix}\n",
    "1 & 3 & 1 \\\\\n",
    "3 & 6 & 3 \\\\\n",
    "1 & 3 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e44061",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_kernel = np.array([\n",
    "    [0, 0, 0]\n",
    "])\n",
    "vertical_kernel = np.array([\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6e9af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3aa24c21302c14212d38aecf82be094",
     "grade": false,
     "grade_id": "cell-0ab4d21924d003ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 5\n",
    "A convolution with the 1D kernels should result in the same output as a single convolution with the 2D kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce89d6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b50176e0588fbddca3093743b9d396dc",
     "grade": true,
     "grade_id": "exercise5_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(horizontal_kernel.shape == (1, 3))\n",
    "assert(vertical_kernel.shape == (3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee2325",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "230ed3ca23aa7553962198d864044459",
     "grade": false,
     "grade_id": "cell-49a7a587dbd26502",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Non-linear filters\n",
    "With convolutions we can easily express and apply linear filters. However, not all image filters are linear. An example of a non-linear filters are the minimum, maximum and median filters. As the names suggest, these filters return the minimum, maximum and median values of the region of $NxN$ pixels surrounding the center pixel. The median filter is an effective way of removing \"salt and pepper\" from images.\n",
    "\n",
    "To prevent confusion, the following image demonstrates a the size of a $3x3$ filter (red border) around the center pixel (blue). Your solution should work for any filter size of $NxN$ where $N$ is an odd number.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/filter_3x3.png\" width=\"50%\"/>\n",
    "</div>\n",
    "\n",
    "### Exercise 6 (2 points)\n",
    "Implement the filters that compute the minimum, maximum and median values respectively inside the $N x N$ region surrounding each pixel. You may assume that the functions will only be called for odd values of $N$. You do not need to handle the case where $N$ is even. At the edges of the image the filter may contain pixels outside of the image. Ignore those pixels and only consider the valid ones (e.g,. taking the min/max/median only of valid pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9d99d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b316544347956cd3fdc9b0225455ea97",
     "grade": false,
     "grade_id": "exercise6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def minimum_filter(gray_image, N):\n",
    "    out = gray_image.copy()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return out\n",
    "\n",
    "def maximum_filter(gray_image, N):\n",
    "    out = gray_image.copy()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return out\n",
    "\n",
    "def median_filter(gray_image, N):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "lena_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"rework\", \"lena_salt_pepper.png\"), scale=0.5)\n",
    "minimum_image = minimum_filter(lena_image, 3)\n",
    "maximum_image = maximum_filter(lena_image, 3)\n",
    "median_image = median_filter(lena_image, 3)\n",
    "helpers.show_images({\n",
    "    \"Input\": lena_image,\n",
    "    \"Median (your solution)\": median_image,\n",
    "    \"Minimum (your solution)\": minimum_image,\n",
    "    \"Maximum (your solution)\": maximum_image\n",
    "}, nrows=2, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb13a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7999332e3bad14eae7518bbf154c0cb",
     "grade": false,
     "grade_id": "cell-6e031252c7bfb954",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 6\n",
    "We provide a couple of basic tests to verify that your functions return images of the correct size and that they don't accidentaly modify the input image. There are two hidden test cells which will test minimum/maximum filters (1 point) and the median filter (1 point).\n",
    "\n",
    "You can add your own tests in the top code cell. Again: try to think of a couple of very simple test cases that you can verify by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f606aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional tests you want to perform here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ceb23c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68e06cd4ba605f07cb1a54125ba31cac",
     "grade": false,
     "grade_id": "cell-2e57546949e80d4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "input_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"rework\", \"lena_salt_pepper.png\"), scale=0.5)\n",
    "input_image_copy = input_image.copy()\n",
    "minimum_image = minimum_filter(lena_image, 5)\n",
    "maximum_image = maximum_filter(lena_image, 5)\n",
    "median_image = minimum_filter(lena_image, 5)\n",
    "assert(helpers.SSD_per_pixel(input_image, input_image_copy) == 0.0) # Your function should not modify the input image\n",
    "assert(input_image.shape == minimum_image.shape)\n",
    "assert(input_image.shape == maximum_image.shape)\n",
    "assert(input_image.shape == median_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc87da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "265449dc2dc7249301c5d93b34faaeed",
     "grade": true,
     "grade_id": "exercise6_tests_a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945daf8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0443f529828a2a1cd86a0cc15309f514",
     "grade": true,
     "grade_id": "exercise6_tests_b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533af28-40e7-4344-89a9-00c4822d0f00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ee7ead81e0204a803918f5e46a15aad",
     "grade": false,
     "grade_id": "cell-1160d549320f6742",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Extra Exercises (Bilateral Blur)\n",
    "The previous exercises are enough to get you a passing grade. However, to get a $10$ you need to show that you have mastered the topic. Therefore, we introduce the following extra exercises which are considered a bit more challenging. You need to complete these without the help of the teaching assistants (TAs). **You not allowed to ask the TAs for help with the extra exercises**. However, you can report bugs by sending us an e-mail at `vdp-cs-ewi@tudelft.nl`.\n",
    "\n",
    "### Exercise 7 (1 points)\n",
    "Gaussian is a commonly used filter to blur images. Implement a function that returns a 2D Gaussian kernel as was described in the lecture. Take the simple approach and evaluate the Gaussian function once for each kernel weight rather than integrating. *Normalize* the result such that weights sum up to $1.0$. The size of the kernel $N$ is guaranteed to be an odd number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6406e-2d35-4aed-98b5-89d13bb81832",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc94fb066c8b053236db1915af6bc749",
     "grade": false,
     "grade_id": "exercise7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaussian_blur_kernel2D(standard_deviation, N):\n",
    "    # Return kernel of size NxN\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "std = 3\n",
    "input_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"rework\", \"racoon.jpg\"), 0.5)\n",
    "blurred_image = scipy.signal.correlate2d(input_image, gaussian_blur_kernel2D(std, 1+6*std), mode=\"same\")\n",
    "helpers.show_images({ \"Input\": input_image, \"Your solution\": blurred_image }, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42a9b2-23a1-46ca-ad7a-ef1906c2a7b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "328b78599313ce70ba54585297e973fa",
     "grade": false,
     "grade_id": "cell-2f1e2edad721a770",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Testing your solution of exercise 7\n",
    "If you implemented exercise 7 correctly then your solution should look blurry. Do not worry about a dark edge around the image; this is caused by the correlation/convolution (`scipy.signal.correlate2d`) operation reading black values outside the image. We provide a couple of basic tests to ensure that some of the basic requirements are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d7b8d-20ab-4596-94fd-023eb71a6cc9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7f5f309c0b592d250bc962b375e9625",
     "grade": true,
     "grade_id": "exercise7_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic check to verify that the returned type is a numpy array of the correct size.\n",
    "std = 4\n",
    "N = 6*std+1\n",
    "kernel = gaussian_blur_kernel2D(std, N)\n",
    "assert(type(kernel) == np.ndarray) # np.array\n",
    "assert(kernel.shape == (N, N))\n",
    "\n",
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226946c5-269c-4eb8-ba19-31d8b478ea24",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fca548c9fc30e77c1cc745e982d6d40",
     "grade": false,
     "grade_id": "cell-0d84ecec99aa7d8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Assignment 8 (2 points)\n",
    "As described in the lecture, a bilateral filter allows us to blur an image while maintaining sharp edges. The bilateral blur combines two different filters: a spatial blur and an intensity based filter.\n",
    "\n",
    "$$\n",
    "J(x) = \\frac{1}{k(x)} \\sum_y^{N \\times N} f(x, y) g(I(x) - I(y)) I(y)\n",
    "$$\n",
    "\n",
    "Here $J(x)$ is the output color of pixel $x$, $y$ is a pixel in the $NxN$ neighbourhood of $x$, $f(x, y)$ is a spatial Gaussian filter (see exercise 7), and $k(x)$ is a normalization term (see lecture slides). $g(...)$ is a 1 dimensional Gaussian filter which assigns weights based on the similarity in intensity between $x$ and $y$. When a neighbouring pixel $y$ has a significantly different color/intensity than pixel $x$ then it is assigned a low weight. This intensity based filtering attempts to prevent blurring over large discontinuities in the image.\n",
    "\n",
    "Implement the intensity filter part of the bilateral blur (effectively a bilateral filter with $f(x, y) = 1$). Again, you may assume that $N$ is an odd number. Ignore neighbours $y$ that fall outside of the image (do not include them in the sum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6af056-623c-49c9-a34b-19442c72b361",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14b730f7a530b80ae9e4a9747f542b05",
     "grade": false,
     "grade_id": "exercise8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bilateral_intensity_filter(image, intensity_standard_deviation, N):\n",
    "    # Return image that filtered using the intensity based Gaussian filter. Do not apply a spatial filter f(x)=1\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "input_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"rework\", \"racoon.jpg\"), 0.3)\n",
    "intensity_blurred_image = bilateral_intensity_filter(input_image, 0.2, 7)\n",
    "std = 2\n",
    "box_blurred_image = cv2.blur(input_image, (7, 7))\n",
    "helpers.show_images({\n",
    "    \"Input\": input_image,\n",
    "    \"Bilateral intensity (your solution)\": intensity_blurred_image,\n",
    "    \"Box blur\": box_blurred_image\n",
    "}, nrows=1, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc9524-b555-4761-bbaa-a42098ade874",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "591ec7cf21da6f62089cd612c75076b9",
     "grade": false,
     "grade_id": "cell-8d764149fbe747e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Testing your solution to exercise 8\n",
    "Your bilateral blur should blur while retaining strong discontinuities in intensity/color such as the eyes of the racoon. In comparison a regular (box) blur will blur over any edges.\n",
    "\n",
    "We provide a couple of simple tests to check if the image you return has the correct size and type. In the cell below you can add your own tests. Try to come up with some simple scenarios (small images) to verify whether your implementation works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52966f6c-b64d-4461-bff9-a53e582ccce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8af6f5-40bf-44b3-a854-66b2bfa2130f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9062675f639b08560a954f279bdea8b9",
     "grade": true,
     "grade_id": "exercise8_tests",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic check to verify that the returned type is a numpy array of the correct size.\n",
    "image_copy = input_image.copy()\n",
    "blurred_image = bilateral_intensity_filter(image_copy, 0.2, 7)\n",
    "assert(type(blurred_image) == np.ndarray) # np.array\n",
    "assert(blurred_image.shape == input_image.shape)\n",
    "assert((image_copy == input_image).all()) # Function should not modify the input\n",
    "\n",
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a10483-e804-4efa-80fa-fe736fce3465",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9bac9162b434ad553440380975b9b3d7",
     "grade": false,
     "grade_id": "cell-68ba999ef965055f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Assignment 9 (1 point)\n",
    "Extend your implementation of assignment 8 by adding a spatial Gaussian filter to create a full bilateral filter implementation. You can call the function that you implemented in exercise 7 to generate the Gaussian filter kernel; it will be replaced by the reference solution when grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa174fea-3f2f-4283-bb88-4f915b11df2d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b07d2f31f53c2ba5910179c7711d9da9",
     "grade": false,
     "grade_id": "exercise9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bilateral_filter(image, intensity_standard_deviation, spatial_standard_deviation, N):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "input_image = helpers.imread_normalized_float_grayscale(os.path.join(helpers.dataset_folder, \"week1\", \"rework\", \"racoon.jpg\"), 0.3)\n",
    "spatial_std = 2\n",
    "bilateral_blurred_image = bilateral_filter(input_image, 0.2, spatial_std, 1+6*spatial_std)\n",
    "gaussian_blurred_image = cv2.GaussianBlur(input_image, (1+6*spatial_std, 1+6*spatial_std), spatial_std)\n",
    "helpers.show_images({\n",
    "    \"Input\": input_image,\n",
    "    \"Bilateral (your solution)\": bilateral_blurred_image,\n",
    "    \"Gaussian blur\": gaussian_blurred_image\n",
    "}, nrows=1, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5e1c2-ec9d-4617-af85-4fc6349df1ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d96e648c5a2ca06259866b90b6aee116",
     "grade": false,
     "grade_id": "cell-f138ea96d0a7f5fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Testing your solution to exercise 9\n",
    "Your bilateral blur should blur while retaining strong discontinuities in intensity/color such as the eyes of the racoon. In comparison a Gaussian blur will blur over any edges.\n",
    "\n",
    "We provide a couple of simple test cases to check if the image you return has the correct size and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e224567-5434-46a6-a1c2-9c60e6408f9e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5b6b3bea434a25a4d910f52aa72642a",
     "grade": true,
     "grade_id": "exercise9_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic check to verify that the returned type is a numpy array of the correct size.\n",
    "image_copy = input_image.copy()\n",
    "blurred_image = bilateral_filter(image_copy, 0.2, 1, 7)\n",
    "assert(type(blurred_image) == np.ndarray) # np.array\n",
    "assert(blurred_image.shape == input_image.shape)\n",
    "assert((image_copy == input_image).all()) # Function should not modify the input\n",
    "\n",
    "# DO NOT REMOVE THIS CELL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
