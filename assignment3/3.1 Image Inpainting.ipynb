{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9510e099a545101efbaa0cf7733c91cc",
     "grade": false,
     "grade_id": "cell-91ecdd51e335450e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import scipy.signal\n",
    "import os\n",
    "# helpers.py is one level up in the directory structure so we need to tell Python were to find it\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import helpers\n",
    "local_data_folder = os.path.join(helpers.dataset_folder, \"week3\", \"inpainting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfdd088b4fb560c4fd1b5a4e4c56ae2a",
     "grade": false,
     "grade_id": "cell-8315cc1f829f08c5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Pull-Push algorithm\n",
    "\n",
    "The Pull-Push algorithm is a simple inpainting technique that fills missing part of an image by propagating mean (average) values from neighboring valid regions. The algorithm proceeds in two phases. First, an image pyramid is build by aggregating valid information from the image (pull). Second, the information from the top of the pyramid is propagated down and interpolated into the previously empty bins (push). This results in each image pixel receiving the information from an image area proportional to the size of the hole as larger holes will generally be filled in higher levels of the pull-push pyramid representing mean of a larger portion of the image. While the technique cannot resolve any higher-order statistical properties (gradients, curvatures,...), it provides a visually continuous transition between the original image content and the smooth inpainted regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "014ab361bcc259f1224adbda53c8d093",
     "grade": false,
     "grade_id": "cell-8cf1d83c8ef069f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 4 (3 points)\n",
    "\n",
    "First, we will implement a step of the pull phase which generates a new image of half the original size.\n",
    "\n",
    "Implement a function that aggregates information from an image $\\mathbf{I^i} \\in \\mathcal{R}^{H \\times W\\times 3}$ into a new image $\\mathbf{I^{i+1}} \\in \\mathcal{R}^{H/2 \\times W/2 \\times 3}$. Each pixel of $\\mathbf{I^{i+1}}$ contains a mean value of valid pixels in a corresponding $2\\times2$ region of $\\mathbf{I^i}$. A pixel is valid if the weight $M^i \\in \\{0,1\\}^{H \\times W\\times 3}$ = 1 at a given location. \n",
    "You can assume that $W = H$ and $W = 2^{k}$ for $k\\in\\mathcal{N}$ (that is $\\mathbf{I^i}$ is a square image with sides divisible by two).\n",
    "\n",
    "As a second output return new pixel weights\n",
    "$$\n",
    "M^{i+1} \\in \\{0,1\\}^{H/2 \\times W/2} =\n",
    "\\begin{cases}\n",
    "    1,             & \\text{if } \\text{at least one of the $2\\times2$ inputs is valid} \\\\\n",
    "    0,             & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Set $\\mathbf{I}^{i+1} = \\mathbf{0}$ where $M^{i+1} = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d266579294e498b25e8deddcbb5331c4",
     "grade": false,
     "grade_id": "exercise5_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pull_next_level(image, weights):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # return (im_next,  weights_next)\n",
    "\n",
    "    \n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"pyramid\", \"im_02.png\"))\n",
    "weights = helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"pyramid\", \"w_02.png\"))\n",
    "image[weights == 0] = 0\n",
    "\n",
    "im_next, weights_next = pull_next_level(image, weights)\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Input image\": image, \n",
    "    \"Output image (your solution)\": im_next,\n",
    "    \"Input weights\": weights, \n",
    "    \"Output weights (your solution)\": weights_next\n",
    "}, nrows=2, ncols=2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a0a4d97d35b33455deb6b3594f82074",
     "grade": false,
     "grade_id": "cell-5bb05722d14f5915",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 4\n",
    "Verify by hand whether you think your solution to exercise 4 is correct. For example: use your mouse to hover over the input image and write down some pixel values in a small region. Work out the expected output by hand and compare it with what your function produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8268d8bd8519f13ab4f174679e1aef94",
     "grade": true,
     "grade_id": "exercise5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6efab91273849d645b647599509d577",
     "grade": false,
     "grade_id": "cell-72cd0683db371ff3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Excercise 5 (2 points)\n",
    "Repeat the pull step to build the entire image pyramid. \n",
    "Return a tuple with two lists: images and weight maps, both lists should be sorted from the largest (= the input) to the smallest.\n",
    "Note, that the last level of the pyramid will be a single pixel image $\\mathbf{I}^N \\in \\mathcal{R}^{1 \\times 1 \\times 3}$ and that $\\mathbf{M}^N = 1$. You can again assume that the input is a square image with sides divisible by two.\n",
    "\n",
    "**NOTE**: For grading we use the reference implementation of `pull_next_level()` to ensure that you are not punished for mistakes in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de6496f6105639bb15d5c86195ecd00b",
     "grade": false,
     "grade_id": "execrise6_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_pyramid(image, weights):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # return pyramid_im, pyramid_w\n",
    "\n",
    "\n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"parrots_256.jpg\"))\n",
    "weights = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"parrots_mask_256.png\")) > 0.5).astype(float)\n",
    "image[weights == 0] = 0\n",
    "\n",
    "pyramid_im, pyramid_w = build_pyramid(image, weights)\n",
    "\n",
    "print(\"Your solution:\")\n",
    "panels = { f\"Image #{i}\": im for i, im in enumerate(pyramid_im)}\n",
    "panels.update({ f\"Weights #{i}\": im for i, im in enumerate(pyramid_w)})\n",
    "helpers.show_images(panels, nrows=2, ncols=len(pyramid_im), col_height=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea03cd08e9f30c271f30dee23f2decf7",
     "grade": false,
     "grade_id": "cell-180deea3ef1229da7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 5\n",
    "Verify your solution by hand using the same method as in exercise 5. We provide a couple of basic tests to ensure that you return the values in the correct format for the grading tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f3c5864487877760d7642e02d81ceeb",
     "grade": true,
     "grade_id": "exercise6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL\n",
    "image = np.ones((128, 128, 3))\n",
    "weights = np.zeros((128, 128))\n",
    "weights[62:64, 64:67] = 0\n",
    "image_pyramid, weights_pyramid = build_pyramid(image, weights)\n",
    "assert(len(image_pyramid) == 8) # 128, 64, 32, 16, 8, 4, 2, 1\n",
    "assert(image_pyramid[1].shape == (64, 64, 3))\n",
    "assert(len(weights_pyramid) == 8) # 128, 64, 32, 16, 8, 4, 2, 1\n",
    "assert(weights_pyramid[1].shape == (64, 64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "173aa0ac2f3dc011372e4e79e8e36daa",
     "grade": false,
     "grade_id": "cell-172a22cb105a3ef4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 6 (4 points)\n",
    "The push phase of the algorithm fills the missing pixels $\\mathbf{x}$ in the (larger) lower pyramid level $\\mathbf{I}^{i}$ by bilinear interpolation of the 4 nearest pixels in (smaller) pyramid level $\\mathbf{I}^{i+1}$ above.\n",
    "\n",
    "The first step is to determine indices of the nearest \n",
    "\n",
    "Now we need to find the 4 nearest pixels $A, B, C, D$ which we interpolate to fill the pixel $\\mathbf{x}$.\n",
    "\n",
    "Below you can see how the small pixels in $\\mathbf{I^i}$ (thin blue lines) overlap with large pixels $a,b,c,d$ in $\\mathbf{I^{i+1}}$ (thick black lines):\n",
    "\n",
    "<img src=\"push_grid3.png\" alt=\"Interpolation grid\" style=\"width: 30%;\"/>\n",
    "\n",
    "While pixels are visualized as square patches, for the interpolation it is important to define their exact location. This is typically done by assigning the pixel color to the center of each pixel (see the circles). We can then compute exact position of any point within the pixel grid with subpixel accuracy.\n",
    "\n",
    "### Example\n",
    "In the image above, the point $\\mathbf{x}^{i} = [2.5, 1.5]$ lies in the center of a pixel $\\mathbf{u}^{i} = [2, 1]$ in the high-resolution image $\\mathbf{I}^{i}$. The same point projected to the low-resolution image $\\mathbf{I}^{i+1}$ will lie in the pixel $\\mathbf{u}^{i+1} = [1, 0]$ and have subpixel coordinates $\\mathbf{x}^{i+1} = [1.25, 0.75]$.\n",
    "\n",
    "The point lies within a $2 \\times 2$ neighborhood defined by the centers of pixels a, b, c, d. Subtracting the position of $a$'s center we get a normalized position of the point as $\\mathbf{x}^{i+1}_{norm} = [0.75, 0.25]$ which can then be used for bilinear interpolation.\n",
    "\n",
    "### Task\n",
    "For a given pixel $\\mathbf{u}^{i}$ of the high-resolution image $\\mathbf{I}^{i}$ (yellow pixel in the Figure) and its center  $\\mathbf{x}^{i}$, find the 4 nearest pixels in $\\mathbf{I}^{i+1}$ (see $a, b, c, d$ in the Figure). Return the integer index of the left-top pixel (see $a$) and the relative subpixel position $\\mathbf{x}^{i+1}_{norm}$ within the 4 neighboring points. \n",
    "\n",
    "Note, that knowledge of the image size or content is not required for this exercise.\n",
    "Assume that the image is infinite, i.e., both positive and negative coordinates are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8d5509672881dfe78f8580f168e17a7",
     "grade": false,
     "grade_id": "exercise7_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def project_point_up(px_coordinate_in_down):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # return index_start, subpixel_position\n",
    "\n",
    "    \n",
    "index_start, subpixel_position = project_point_up(np.array([2,1]))\n",
    "print(\"Input point [3, 1]\")\n",
    "print(f'The nearest left-top pixel in the smaller image is {index_start}.')\n",
    "print(f'The normalized position is {subpixel_position}.')\n",
    "print(f'The reference solution is [1, 0] and [0.25, 0.25]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f94fa7418f2390708edf5c0abece11d",
     "grade": false,
     "grade_id": "cell-180deea3ef1229a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 6\n",
    "Try to come up with more inputs and work them out by hand. Does your solution produce the correct result for these cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25ce95e829806648c8a45041efcfea3b",
     "grade": true,
     "grade_id": "exercise7",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd022840d13eb4e98f76fb2e7aa0bff5",
     "grade": false,
     "grade_id": "cell-fbb20375b8ca29cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 7 (2 points)\n",
    "Next, we need to combine the colors from the 4 nearest pixels using bilinear interpolation.\n",
    "\n",
    "Given the 4 nearest pixel color values $\\{\\mathbf{I}^{i}(\\mathbf{a}), \\mathbf{I}^{i}(\\mathbf{b}), \\mathbf{I}^{i}(\\mathbf{c}), \\mathbf{I}^{i}(\\mathbf{d})\\} \\in \\mathcal{R}^{4\\times3}$ and a normalized point position $\\mathbf{x} = (\\alpha, \\beta) \\in [0,1]\\times[0,1]$, compute interpolated value using bilinear interpolation.\n",
    "\n",
    "<img src=\"bilinterp.png\" alt=\"Interpolation grid\" style=\"width: 30%;\"/>\n",
    "\n",
    "Bilinear interpolation is a weighted mean of 4 corner values with weights proportional to areas of rectangle adjacent to each of the source vertices. It can also be separated into 3 one-dimensional linear interpolations by first interpolating the the between $a$ and $b$, and $d$ and $c$ using $\\alpha$ and then interpolating the intermediate results in an orthogoval dimension defined by $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8440daea6f06e6014d6a7001660d6339",
     "grade": false,
     "grade_id": "exercise8_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bilinear_interpolation(col_a, col_b, col_c, col_d, x):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # return res\n",
    "\n",
    "a = np.array([1.0, 0, 0])\n",
    "b = np.array([0, 1.0, 0])\n",
    "c = np.array([0, 0, 1.0])\n",
    "d = np.array([1.0, 1.0, 1.0])\n",
    "x = np.array([0.75, 0.25])\n",
    "\n",
    "interpolated = bilinear_interpolation(a,b,c,d,x)\n",
    "\n",
    "print(f'The interpolated color at {x} was computed as {np.array2string(interpolated, precision=3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c334f016c623ec3220e061edb89f625",
     "grade": false,
     "grade_id": "cell-fc621e575014bcd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 7\n",
    "Try to come up with more inputs and work them out by hand. Does your solution produce the correct result for these cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6b4c9985de830c3b9063cdba1bcb5b9",
     "grade": true,
     "grade_id": "exercise8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "277889285caf93dedb005da63da6e337",
     "grade": false,
     "grade_id": "cell-5acac4435d84da61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 8 (4 points)\n",
    "\n",
    "Now we can combine Excercise 6 and 7 together and implement an entire push phase. \n",
    "\n",
    "Implement a method that collapses the image pyramid $\\mathbf{I}^{0..N}$ in the up-down direction and fills missing pixels in each larger high-resolution image $\\mathbf{I}^{i}$ by interpolating a corresponding low-resolution image $\\mathbf{I}^{i+1}$.\n",
    "Do not modify pixels that are marked as valid in the provided weights map $M^{i}$.\n",
    "\n",
    "### Notes\n",
    "Visit every level of the pyramid from the top to the bottom.\n",
    "Test every output pixel and update values of those pixels that are not yet valid. \n",
    "For each such pixel find the 4 neighboring low-resolution pixels and relative pixel position using the code from Exercise 6.\n",
    "Use the relative position as bilinear interpolation weights.\n",
    "Take a special care for pixels that lie close to the image boundary as one of the four neighbors can lie outside of $\\mathbf{I}^{i+1}$. Clamp the coordinates of such neighbor pixel to the domain on $\\mathbf{I}^{i+1}$.\n",
    "\n",
    "For grading we use the reference implementation of `project_point_up()` and `bilinear_interpolation` to ensure that you are not punished for mistakes in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae5e507e486040ee4c0aaf9c476b8108",
     "grade": false,
     "grade_id": "exercise9_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def push_pyramid(im_pyramid, w_pyramid):\n",
    "    # Interpolate im_pyramid[i+1] to fill im_pyramid[i] where w_down == 0.\n",
    "    # Modify im_pyramid in-place (do not edit a copy).\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    \n",
    "im_files = sorted(helpers.list_files_in_folder(os.path.join(local_data_folder, 'pyramid'), filter=\"im_*.png\"))\n",
    "im_pyramid = [helpers.imread_normalized_float(f) for f in im_files]\n",
    "w_files = sorted(helpers.list_files_in_folder(os.path.join(local_data_folder, 'pyramid'), filter=\"w_*.png\"))\n",
    "w_pyramid = [helpers.imread_normalized_float_grayscale(f) for f in w_files]\n",
    "\n",
    "print(\"Your solution:\")\n",
    "panels = { f\"Image #{i}\": im for i, im in enumerate(im_pyramid)}\n",
    "panels.update({ f\"Weights #{i}\": im for i, im in enumerate(w_pyramid)})\n",
    "helpers.show_images(panels, nrows=2, ncols=len(im_pyramid), col_height=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f3e2685bf63a13a2535b46ab6bb0e15",
     "grade": false,
     "grade_id": "cell-0e6e0695bff91943",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 8\n",
    "The image pyramid should now not contain any holes anymore. Verify that the interpolated values are correct by creating a simple test case (e.g. 4x4 image that you create yourself) and verify that bilinear interpolation is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd1025e75fda2d5134e1221cadd4d528",
     "grade": true,
     "grade_id": "exercise9",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48bd695b210dfa910ab902ca0942ec99",
     "grade": false,
     "grade_id": "cell-289e2c3a8d7a6166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Full Algorithm\n",
    "Now we have all the necessary components of a complete Pull-Push algorithm and we can use it for image inpainting.\n",
    "In this example we will remove red text caption that has been embedded into a photograph.\n",
    "\n",
    "We recommend you to also try other images and masks. Can you come up with an example where the Pull/Push algorithm doesn't work as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee213454ecd9c924c555dc1038bafc30",
     "grade": false,
     "grade_id": "exercise10_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "714e3f7d35d375bb9bb4d36dbcc5fdd5",
     "grade": false,
     "grade_id": "cell-c3ed06cc734f5ded",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Extra Exercises (Patch Based Inpainting)\n",
    "The previous exercises are enough to get you a passing grade. However, to get a $10$ you need to show that you have mastered the topic. Therefore, we introduce the following extra exercises which are considered a bit more challenging. You need to complete these without the help of the teaching assistants (TAs). **You not allowed to ask the TAs for help with the extra exercises**. However, you can report bugs by sending us an e-mail at `vdp-cs-ewi@tudelft.nl`.\n",
    "\n",
    "With pull-push you have implemented an inpainting technique based on low-level statistics. For these extra exercises you will implement (a part of) the patch based inpainting technique from the paper [Region filling and object removal by exemplar-based image inpainting](https://www.irisa.fr/vista/Papers/2004_ip_criminisi.pdf) which was also described in class. The idea is to take patches (small square regions) from the known image and paste them into the missing pixels. The trick here is to find the most suitable patch and to fill in an appropriate order.\n",
    "\n",
    "### Selecting the next patch\n",
    "We are given an image $J$ with unknown pixels defined by a second mask image, similar to the previous exercises (with $1$ for known pixels and $0$ for unknown pixels). To select the next region to inpaint we consider the unknown pixels on the boundary between the known/unknown regions of the image. For each of those pixels we consider filling the patch centered at that pixel. Out of those the patch of unknown pixels that needs to be filled is selected by maximizing the following equation:\n",
    "\n",
    "$$P(p) = C(p) * D(p)$$\n",
    "\n",
    "The goal of the data term $D(p)$ is to select patches in such a way that edges or lines in the image are inpainted first, before inpainting more flat/uniform regions. The data term is defined as the length of the projection of the isophote (edge/line in the image) and the normal vector of the inpainting boundary. The isophote is computed orthogonal to the maximum magnitude gradient between known pixels inside the patch. The normal vector of the known/unknown region boundary is computed by taking the difference between the current boundary pixel and the next boundary pixel.\n",
    "\n",
    "<img src=\"images/data_term.png\" alt=\"Data Term\" style=\"height: 25em;\"/>\n",
    "\n",
    "When inpainting we continuously select a patch on the boundary of the unknown region, fill it by copy & pasting values from another patch, and continue untill the whole image is filled. We cannot be sure however that the colours that we picked to fill preceding patches accurately represent what was supposed to be there. Therefore, our confidence in the value of those pixels, and thus the data term, drops. This effect is tracked for step $k$ in a confidence image $C_k(q)$ which, like the image mask, starts as $C_0(q)$ with $1.0$ for all known pixels (100% confident) and $0.0$ for unknown pixels. The confidence value $C_k(p)$ is defined as the mean $C_{k-1}(q)$ value for all pixels inside the patch. When a patch is selected for inpainting in step $k$ the confidence values $C_k(q)$ of unknown pixels in the patch are updated using the confidence values $C_{k-1}(p)$ from the previous step.\n",
    "\n",
    "<img src=\"images/confidence_term.png\" alt=\"Confidence Term\" style=\"height: 25em;\"/>\n",
    "\n",
    "\n",
    "### Exercise 9 (1 point)\n",
    "For this exercise you will implement the confidence term $C_k(p)$ as described above (and in the lecture). Your function takes the confidence image $C_{k-1}(q)$, the pixel at the center of the patch, and the patch size. You can use the helper function `slice_patch` to get the patch from an image. You do not need to handle patches that lie (partially) outside the image because we guarantee that no such patches will be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a00ba2c6a38086af831b346080c04f6c",
     "grade": false,
     "grade_id": "cell-a7741ff6aefbc3f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "def slice_patch(image, x, y, patch_size):\n",
    "    half_patch_size = patch_size // 2\n",
    "    return image[y-half_patch_size:y+half_patch_size+1, x-half_patch_size:x+half_patch_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f499ac98f5f13bfb3890327cf062b794",
     "grade": false,
     "grade_id": "cell-b6d1fce3e4dc1cef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_confidence_term(confidence_image, x, y, patch_size):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8f7f56a1109a115c9a03035e851ea9a",
     "grade": false,
     "grade_id": "cell-2f8dfcb585dc73b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Testing your solution of exercise 9\n",
    "Come up with some additional test cases (images) to convince yourself that your solution is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"canyonlakedrive.jpg\"), 0.35)\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"canyonlakedrive_mask.png\"), 0.35) < 0.5)\n",
    "image[mask == 0] = 0\n",
    "\n",
    "# Compute boundary pixels\n",
    "confidence_image_cq = mask.copy()\n",
    "confidence_term_cp = np.zeros(mask.shape)\n",
    "patch_size = 9\n",
    "for y, x in zip(*np.where(mask == 0)):\n",
    "    if np.sum(image[y-1:y+2,x-1:x+2]) > 0:\n",
    "        confidence_term_cp[y, x] = compute_confidence_term(confidence_image_cq, x, y, patch_size)\n",
    "\n",
    "helpers.show_images({\n",
    "    'Confidence Image $C_{k-1}(q)$': mask,\n",
    "    'Confidence Term $C_k(p)$': confidence_term_cp\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e65601ba21a81a3448cf40a6b56d3363",
     "grade": true,
     "grade_id": "cell-40b3a81f6fe15fbf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1c8e33e99e0d0d2aa3cef478fd36173",
     "grade": false,
     "grade_id": "cell-ee2e65479459b721",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Data Term\n",
    "In order to compute the data term $D(p)$ we need to define the normal vector of the boundary. This is computed by comparing the current boundary pixel position to its neighbours positions. To ease this computation we store the boundary pixels in clock-wise order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b068853ebdecdbcbecd53121bef62369",
     "grade": false,
     "grade_id": "cell-84c8949caecf9237",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find all boundary pixels (fill front) in clock wise order (must be sorted to compute data term)\n",
    "def compute_fill_front(target_mask):\n",
    "    # If there are no pixels to fill then we are done.\n",
    "    if np.sum(1 - target_mask) == 0:\n",
    "        return []\n",
    "    \n",
    "    # We need to find a starting point. We find an unknown pixel which might be a boundary pixel but could also lie deeper in the unknown region.\n",
    "    # So we visit all pixels in that row (same y coordinate) from left to right to find the first boundary pixel.\n",
    "    first_y, _ = next(zip(*np.where(target_mask == 0)))\n",
    "    for first_x in range(target_mask.shape[1]):\n",
    "        if target_mask[first_y, first_x] == 0:\n",
    "            break\n",
    "    \n",
    "    fill_front = [] # Sorted output\n",
    "    visited_pixels = set() # Contains the currently visited set of pixels (same as fill front but a set() instead of list() for faster lookups)\n",
    "    \n",
    "    # The potential neighbours to consider (relative to the current pixel) in *clockwise* order.\n",
    "    directions = [(-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0)]\n",
    "    current_direction = 0 # Current direction that we are following along the boundary\n",
    "    x, y = first_x, first_y # x and y coordinates of the current boundary pixel\n",
    "    done = False # Track whether we are done (finished the circle)\n",
    "    while not done:\n",
    "        # Add the current boundary pixel to the output\n",
    "        fill_front.append((x, y))\n",
    "        visited_pixels.add((x, y))\n",
    "        \n",
    "        # Start by trying to go backwards (current_direction + 4) and from there visit the neighbours in clockwise order.\n",
    "        done = True\n",
    "        direction = current_direction + 4\n",
    "        for i in range(len(directions)):\n",
    "            dx, dy = directions[(direction + i) % len(directions)]\n",
    "            nx, ny = x + dx, y + dy\n",
    "            # A pixel is a boundary pixel if its value is unknown and at least one of its (8 connected) neighbours is known.\n",
    "            is_neighbour_on_boundary = np.sum(target_mask[ny-1:ny+2,nx-1:nx+2]) > 0 and target_mask[ny, nx] == 0\n",
    "            if is_neighbour_on_boundary and (nx, ny) not in visited_pixels: # Skip neighbours that we've already visited\n",
    "                x, y = nx, ny # Visit the neighbour\n",
    "                current_direction = (direction + i) % len(directions)\n",
    "                done = False # We visited a new neighbour so we are not done yet\n",
    "                break # Stop the clockwise visiting and go to the neighbour we just selected\n",
    "    \n",
    "    return fill_front\n",
    "\n",
    "\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"line_mask.png\"), 1) > 0.5)\n",
    "fill_front = compute_fill_front(mask)\n",
    "\n",
    "image = np.zeros(mask.shape)\n",
    "for i, (x, y) in enumerate(fill_front):\n",
    "    image[y, x] = i / len(fill_front)\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Known/unknown pixels mask\": mask,\n",
    "    \"Fill Front / boundary\": image\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5ec5cfdc8bf1a68602f5eca536f9647",
     "grade": false,
     "grade_id": "cell-e5b156781be3ee6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Exercise 10 (4 points)\n",
    "After determining the fill front (in order) we can now compute the data term. The data term function takes a list of pixels along the fill front (to compute the normal) and computes for each of those pixels the data term $D(p)$. The isophote for each boundary pixel is computed from the gradient with the maximum magnitude in the patch around the pixel.\n",
    "\n",
    "**Tip**: remember that the isophote is parallel to an edge and not orthognal like a gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd5982402a32db79ac0dae34813ad11d",
     "grade": false,
     "grade_id": "cell-753cbbe72dd680cc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    return np.array(v) / np.linalg.norm(v)\n",
    "    \n",
    "\n",
    "def compute_data_term_along_fill_front(image, target_mask, patch_size, fill_front):\n",
    "    gray_image = helpers.rgb2gray(image)    \n",
    "    gradient_x = scipy.signal.correlate2d(gray_image, [[-0.5, 0, +0.5]], mode=\"same\", boundary=\"symm\")\n",
    "    gradient_y = scipy.signal.correlate2d(gray_image, [[-0.5], [0], [+0.5]], mode=\"same\", boundary=\"symm\")\n",
    "    \n",
    "    # Mask out pixels for which a neighbour is unknown (and thus the gradient is invalid)\n",
    "    grown_mask = 1 - (scipy.signal.correlate2d(1-target_mask, [[0,1,0], [1,0,1],[0,1,0]], mode=\"same\") > 0)\n",
    "    gradient_x *= grown_mask\n",
    "    gradient_y *= grown_mask\n",
    "    \n",
    "    out = []\n",
    "    for (xl, yl), (x, y), (xr, yr) in zip(fill_front[-1:] + fill_front[:-1], fill_front, fill_front[1:] + fill_front[:1]):\n",
    "        # Normal of the boundary.\n",
    "        n_p = normalize([yl-yr, xr-xl]) # (xr-xl, yr-yl) is parallel to the boundary; (-(yr-yl), xr-xl) is orthogonal to the boundary.\n",
    "    \n",
    "        # ======================\n",
    "        # === ADD CODE BELOW ===\n",
    "        # ======================\n",
    "        # For the patch of patch_size around the pixel (x, y) (as returned by the slice_patch() method),\n",
    "        # compute the isophote using the largest gradient within the patch. The largest gradient is found using L2 norm. \n",
    "        # Note that the isophote is defined to be orthogonal to the gradient.\n",
    "        # Use the isophote and normal of the boundary to compute the data term D(p) and store the result in the variable \"D_p\".\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        out.append(D_p)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a1fa3f2c70c8c531281335548632d80",
     "grade": false,
     "grade_id": "cell-b0438220188e2934",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Testing your solution of exercise 10\n",
    "The following code displays the data term for the whole image. The data term values are multiplied by three to increase visibility. Try to come up with some additional test cases (images) to convince yourself that your solution is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"canyonlakedrive.jpg\"), 0.35)\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"canyonlakedrive_mask.png\"), 0.35) < 0.5)\n",
    "image[mask == 0] = 0\n",
    "\n",
    "patch_size = 9\n",
    "\n",
    "fill_front = compute_fill_front(mask)\n",
    "fill_front = [(x, y) for x, y in fill_front if x > 3 and y > 3]\n",
    "data_term_on_fill_front = compute_data_term_along_fill_front(image, mask, patch_size, fill_front)\n",
    "\n",
    "# Create an image showing the value of D(p) along the fill front / boundary\n",
    "data_term_image = np.zeros(mask.shape)\n",
    "for (x, y), D_p in zip(fill_front, data_term_on_fill_front):\n",
    "    data_term_image[y, x] = D_p\n",
    "\n",
    "helpers.show_images({\n",
    "    'Input': helpers.rgb2gray(image),\n",
    "    '3x Data Term ($3 \\cdot D(p)$)': data_term_image * 3\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b738f462338d2a545e793afeffd9e532",
     "grade": true,
     "grade_id": "cell-a821eefb7ccece9a",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d323d3d2a03a5ba771a31134815a2b26",
     "grade": false,
     "grade_id": "cell-141f80a3604949b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Finding a matching patch\n",
    "Once a *query* patch has been selected for inpainting (using product of the confidence & data terms) the algorithm needs to find new values to assign to unknown pixels inside the patch. The algorithm is based on the idea of copy & pasting patches from other (known) parts of the image. All *complete* patches (patches fully inside the image with no unknown pixels) are visited and compared to the *query* patch and the most similar one is used for copy and pasting.\n",
    "\n",
    "Similarity between the *query* patch and other (complete) patches is defined as the sum of squared differences over the *known* pixels. Unknown pixels (that need to be filled in) should be excluded from this sum.\n",
    "\n",
    "### Exercise 11 (4 points)\n",
    "Implement a function that given a query patch (patch of `patch_size*patch_size` around `(query_x, query_y)`) searches the image for the most similar *complete* patch using the method described above. The returned patch is again defined by its center pixel position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9af81ddb0e72b23e68b60159d55996c",
     "grade": false,
     "grade_id": "cell-dd8156b55f63bcc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "def find_most_similar_patch(image, target_mask, query_x, query_y, patch_size):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fffaf5ed941973cc2639f2fc6d6a0d4",
     "grade": false,
     "grade_id": "cell-43f9e7ef9b3ececd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Testing your solution of exercise 11\n",
    "The following code displays a query patch and the most similar patch as found by your implementation. Try to come up with some additional test cases (patches) to convince yourself that your solution is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"canyonlakedrive.jpg\"), 0.35)\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"canyonlakedrive_mask.png\"), 0.35) < 0.5)\n",
    "image[mask == 0] = 0\n",
    "\n",
    "patch_size = 9\n",
    "half_patch_size = patch_size // 2\n",
    "\n",
    "query_y, query_x = next(zip(*np.where(mask == 0)))\n",
    "match_x, match_y = find_most_similar_patch(image, mask, query_x, query_y, patch_size)\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Query patch\": slice_patch(image, query_x, query_y, patch_size),\n",
    "    \"Most similar complete patch (your solution)\": slice_patch(image, match_x, match_y, patch_size),\n",
    "    \"Absolute Pixel Differences:\": slice_patch(mask, query_x, query_y, patch_size) * np.mean(np.abs(slice_patch(image, query_x, query_y, patch_size) - slice_patch(image, match_x, match_y, patch_size)), axis=2)\n",
    "}, ncols=3, nrows=1)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "ax1.set_title(\"Query Patch (Red); Most Similar Patch (Cyan)\")\n",
    "ax1.imshow(image)\n",
    "ax1.add_patch(patches.Rectangle((query_x - half_patch_size, query_y - half_patch_size), patch_size, patch_size, fill=False, edgecolor=\"red\", linewidth=3))\n",
    "ax1.add_patch(patches.Rectangle((match_x - half_patch_size, match_y - half_patch_size), patch_size, patch_size, fill=False, edgecolor=\"cyan\", linewidth=3))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9346a291940cbc37f5593b26083daf0b",
     "grade": true,
     "grade_id": "cell-1abeb3acf03ad7b0",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "422c894ab1eec7304591e52c1c9cf649",
     "grade": false,
     "grade_id": "cell-cfa64c8349dcf864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Inpainting\n",
    "With the exercises implemented it is now possible to run the complete inpainting algorithm. In a continuous loop the highest priority patch is selected (exercises 9 & 10). The most similar complete image patch is found (exercise 11) and values from that patch are pasted into the unknown pixels of the selected query patch. Finally the unknown pixels in the confidence image $C_k(p)$ is updated from the value of $C_{k-1}(q)$.\n",
    "\n",
    "The full inpainting algorithm is implemented below and should succesfully remove the Hollywood sign from Mount Lee. The inpainting process is visualized interactively: the image is updated after each step. Don't worry if it takes a couple minutes to perform the inpainting; this is not part of the grading tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd816e2063eaa7dec425c5bc27c3a2ed",
     "grade": false,
     "grade_id": "cell-20e92b7a9e9fb0ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from IPython import display\n",
    "import os\n",
    "\n",
    "def select_highest_priority_patch(image, confidence_image, target_mask, fill_front, patch_size):\n",
    "    confidence_term = [compute_confidence_term(confidence_image, x, y, patch_size) for x, y in fill_front]\n",
    "    data_term = compute_data_term_along_fill_front(image, target_mask, patch_size, fill_front)\n",
    "    priority = np.array(confidence_term) * np.array(data_term)\n",
    "    selected_index = np.argmax(priority)\n",
    "    return (fill_front[selected_index], confidence_term[selected_index])\n",
    "\n",
    "def patch_based_inpainting(image, target_mask, patch_size):\n",
    "    confidence_image = np.zeros(target_mask.shape)\n",
    "    confidence_image[mask == 0] = 1\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    fig.show()\n",
    "    \n",
    "    num_pixels_to_fill = np.sum(1 - target_mask)\n",
    "    image = image.copy()\n",
    "    with progressbar.ProgressBar(maxval = num_pixels_to_fill) as bar:\n",
    "    #with progressbar.ProgressBar(max_value = num_pixels_to_fill) as bar:\n",
    "        while True:\n",
    "            bar.update(num_pixels_to_fill - np.sum(1 - target_mask)) # Number of pixels that have not been filled yet.\n",
    "            fill_front = compute_fill_front(target_mask)\n",
    "            if not fill_front:\n",
    "                break\n",
    "\n",
    "            (x, y), confidence = select_highest_priority_patch(image, confidence_image, target_mask, fill_front, patch_size+4)\n",
    "            qx, qy  = find_most_similar_patch(image, target_mask, x, y, patch_size)\n",
    "            mask_patch = slice_patch(target_mask, x, y, patch_size)\n",
    "            out_patch = slice_patch(image, x, y, patch_size)\n",
    "            in_patch = slice_patch(image, qx, qy, patch_size)\n",
    "            for dy in range(patch_size):\n",
    "                for dx in range(patch_size):\n",
    "                    if mask_patch[dy, dx] == 0:\n",
    "                        out_patch[dy, dx, :] = in_patch[dy, dx, :]\n",
    "            slice_patch(confidence_image, x, y, patch_size)[:] = confidence\n",
    "            mask_patch[:] = 1 # Set the mask to 1 pixels in the patch\n",
    "\n",
    "            ax.imshow(image, interpolation=\"None\")\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(fig)\n",
    "        \n",
    "    return image\n",
    "\n",
    "\n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"canyonlakedrive.jpg\"), 0.35)\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"canyonlakedrive_mask.png\"), 0.35) < 0.5)\n",
    "original_image = image.copy()\n",
    "image[mask == 0] = 0\n",
    "# Don't execute the inpainting algorithm when grading\n",
    "if os.environ.get(\"NBGRADER_EXECUTION\") != \"autograde\" and os.environ.get(\"NBGRADER_EXECUTION\") != \"validate\":\n",
    "    clean_image = patch_based_inpainting(image, mask, 9)\n",
    "\n",
    "helpers.show_images({\n",
    "    'Input': original_image,\n",
    "    'Output': clean_image\n",
    "}, nrows=1, ncols=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e23ee5192b0758591530755eb1daadb41813c448255c459cb26f125197f59a99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
